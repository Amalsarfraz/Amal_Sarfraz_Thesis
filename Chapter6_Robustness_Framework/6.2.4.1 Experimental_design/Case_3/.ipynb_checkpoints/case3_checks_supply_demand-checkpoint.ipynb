{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c833a60-0ea3-412c-b8cf-38eaf6a88f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from scipy.stats import qmc\n",
    "\n",
    "def assure_path_exists(path):\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"Creating directory: {path}\")\n",
    "        os.makedirs(path)\n",
    "    else:\n",
    "        print(f\"Directory already exists: {path}\")\n",
    "\n",
    "def month_range_str(start_month):\n",
    "    months = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "    return f\"{months[start_month]}-{months[(start_month+1)%12]}-{months[(start_month+2)%12]}\"\n",
    "\n",
    "\n",
    "\n",
    "def lhs_params(param_ranges, n_samples):\n",
    "    n_params = len(param_ranges)\n",
    "    sampler = qmc.LatinHypercube(d=n_params)\n",
    "    lhs_samples = sampler.random(n=n_samples)\n",
    "    for i in range(n_params):\n",
    "        min_val, max_val = param_ranges[i]\n",
    "        lhs_samples[:, i] = min_val + (max_val - min_val) * lhs_samples[:, i]\n",
    "    return lhs_samples\n",
    "\n",
    "\n",
    "\n",
    "def generate_demand_flows(demand_samples):\n",
    "    demand_param_ranges = {\n",
    "        \"Cotton\": [6.2844, 106.5503],\n",
    "        \"Rice\": [0.000000, 86.1922],\n",
    "        \"Wheat\": [0.7141, 97.3107],\n",
    "        \"Sugarcane\": [1.2042, 162.1384],\n",
    "        \"Miscellaneous\": [3.3697, 47.7030],\n",
    "    }\n",
    "    crop_percentages = {\n",
    "        'Cotton': [0.00, 0.00, 0.00, 0.00, 0.10, 0.15, 0.20, 0.20, 0.15, 0.15, 0.05, 0.00],\n",
    "        'Rice': [0.00, 0.00, 0.00, 0.00, 0.00, 0.25, 0.25, 0.20, 0.20, 0.10, 0.00, 0.00],\n",
    "        'Wheat': [0.20, 0.25, 0.25, 0.15, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.15],\n",
    "        'Sugarcane': [0.083] * 12,\n",
    "        'Miscellaneous': [0.083] * 12\n",
    "    }\n",
    "    \n",
    "    demand_flows = {}\n",
    "    for i, crop in enumerate(demand_param_ranges.keys()):\n",
    "        annual_demands = demand_samples[:, i]\n",
    "        monthly_demands = np.outer(annual_demands, crop_percentages[crop])\n",
    "        demand_flows[crop] = monthly_demands\n",
    "        print(f\"{crop} Demand Range: {np.min(annual_demands):.3f} - {np.max(annual_demands):.3f}\")\n",
    "    return demand_flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a814dadf-255c-426b-9632-a6779a0cebac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_var_metrics(supply_data, demand_flows, current_storage, potential_storage):\n",
    "    n_scenarios = len(supply_data)\n",
    "    \n",
    "    annual_scarcity = np.zeros(n_scenarios)\n",
    "    surplus_capacity = np.zeros(n_scenarios)\n",
    "    deficit_severity = np.zeros(n_scenarios)\n",
    "    variability = np.zeros(n_scenarios)\n",
    "    best_months = np.zeros(n_scenarios, dtype=int)\n",
    "    worst_months = np.zeros(n_scenarios, dtype=int)\n",
    "    storage_adequacy = np.zeros(n_scenarios)\n",
    "    storage_adequacy_points = np.zeros(n_scenarios, dtype=int)\n",
    "    \n",
    "    for i in range(n_scenarios):\n",
    "        monthly_supply = np.mean(supply_data[i], axis=0)\n",
    "        monthly_demand = np.sum([demand_flows[crop][i] for crop in demand_flows], axis=0)\n",
    "        \n",
    "        annual_supply = np.sum(monthly_supply)\n",
    "        annual_demand = np.sum(monthly_demand)\n",
    "        annual_scarcity[i] = annual_demand / annual_supply\n",
    "        \n",
    "        extended_supply = np.concatenate([monthly_supply[-2:], monthly_supply, monthly_supply[:2]])\n",
    "        extended_demand = np.concatenate([monthly_demand[-2:], monthly_demand, monthly_demand[:2]])\n",
    "        \n",
    "        rolling_supply = np.convolve(extended_supply, np.ones(3), 'valid') /3\n",
    "        rolling_demand = np.convolve(extended_demand, np.ones(3), 'valid') /3\n",
    "        \n",
    "        rolling_balance = rolling_supply - rolling_demand\n",
    "        \n",
    "        best_balance = np.max(rolling_balance)\n",
    "        worst_balance = np.min(rolling_balance)\n",
    "        variability[i] = best_balance - worst_balance\n",
    "        \n",
    "        best_months[i] = np.argmax(rolling_balance) % 12\n",
    "        worst_months[i] = np.argmin(rolling_balance) % 12\n",
    "        \n",
    "        surplus_capacity[i] = best_balance\n",
    "        deficit_severity[i] = -worst_balance\n",
    "        \n",
    "        storage_adequacy[i] = current_storage / variability[i]\n",
    "        \n",
    "        if variability[i] <= current_storage:\n",
    "            storage_adequacy_points[i] = 2  # Can meet with current storage\n",
    "        elif variability[i] <= (current_storage + potential_storage):\n",
    "            storage_adequacy_points[i] = 1  # Can meet with potential storage\n",
    "        else:\n",
    "            storage_adequacy_points[i] = 0  # Cannot meet with either\n",
    "    \n",
    "    return annual_scarcity, variability, surplus_capacity, deficit_severity, best_months, worst_months, storage_adequacy, storage_adequacy_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b71dce-471a-4f99-adc0-f24cdd861bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_lambda_vs_amplitude_updated_again(data, metrics, output_file):\n",
    "    descriptive_labels = {\n",
    "        'Deficit_Severity': 'Deficit Severity',\n",
    "        'Surplus_Capacity': 'Surplus Capacity',\n",
    "        'Variability': 'Variability'\n",
    "    }\n",
    "    fig, axs = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    fig.suptitle('Lambda vs Amplitude', fontsize=16)\n",
    "    \n",
    "    axs = axs.flatten()\n",
    "    subplot_labels = ['(a)', '(b)', '(c)', '(d)', '(e)']\n",
    "    \n",
    "    for i, metric in enumerate(metrics):\n",
    "        ax = axs[i]\n",
    "        \n",
    "        if metric == 'Annual_Scarcity':\n",
    "            scatter = ax.scatter(data['Input_lambda'], data['Input_Amplitude'], \n",
    "                                 c=data[metric], cmap='coolwarm')\n",
    "            ax.set_title(f'Annual Scarcity')\n",
    "            plt.colorbar(scatter, ax=ax, label='Annual Scarcity')\n",
    "        \n",
    "        elif metric in ['Deficit_Severity', 'Surplus_Capacity', 'Variability']:\n",
    "            scatter = ax.scatter(data['Input_lambda'], data['Input_Amplitude'], \n",
    "                                 c=data[metric], cmap='coolwarm')\n",
    "            ax.set_title(descriptive_labels[metric])\n",
    "            cbar = plt.colorbar(scatter, ax=ax)\n",
    "            cbar.set_label(descriptive_labels[metric], rotation=270, labelpad=15)\n",
    "        \n",
    "        elif metric == 'Storage_Adequacy_Points':\n",
    "            colors = ['red' if val == 0 else 'yellow' if val == 1 else '#1f77b4' for val in data[metric]]\n",
    "            scatter = ax.scatter(data['Input_lambda'], data['Input_Amplitude'], c=colors)\n",
    "            ax.set_title('Storage Adequacy')\n",
    "            \n",
    "            from matplotlib.lines import Line2D\n",
    "            legend_elements = [Line2D([0], [0], marker='o', color='w', label='Inadequate (0)',\n",
    "                                      markerfacecolor='red', markersize=10),\n",
    "                               Line2D([0], [0], marker='o', color='w', label='Adequate for Potential (1)',\n",
    "                                      markerfacecolor='yellow', markersize=10),\n",
    "                               Line2D([0], [0], marker='o', color='w', label='Adequate for Current and Potential (2)',\n",
    "                                      markerfacecolor='#1f77b4', markersize=10)]\n",
    "            ax.legend(handles=legend_elements, loc='best')\n",
    "        \n",
    "        ax.set_xlabel('Lambda')\n",
    "        ax.set_ylabel('Amplitude')\n",
    "        ax.text(0.03, 1.07, subplot_labels[i], transform=ax.transAxes, fontsize=12,\n",
    "                verticalalignment='top', bbox=dict(boxstyle='round,pad=0.3', edgecolor='none', facecolor='white'))\n",
    "    \n",
    "    fig.delaxes(axs[5])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_file, bbox_inches='tight', dpi=600)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0dbb199-9df7-4721-a167-5f2bb946e747",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    sites = ['All']  \n",
    "    nMonths = 12\n",
    "    n_samples = 1000\n",
    "\n",
    "    # Supply parameter ranges\n",
    "    supply_param_ranges = [\n",
    "        [0.47, 1.78],  # Amplitude\n",
    "        [0, 1]         # lambda\n",
    "    ]\n",
    "\n",
    "    # Demand parameter ranges\n",
    "    demand_param_ranges = [\n",
    "        [6.2844, 106.5503],   # Cotton\n",
    "        [0.000000, 86.1922],  # Rice\n",
    "        [0.7141, 97.3107],    # Wheat\n",
    "        [1.2042, 162.1384],   # Sugarcane\n",
    "        [3.3697, 47.7030],    # Miscellaneous\n",
    "    ]\n",
    "\n",
    "    # Generate LHS samples for supply and demand\n",
    "    supply_lhs_samples = lhs_params(supply_param_ranges, n_samples)\n",
    "    demand_lhs_samples = lhs_params(demand_param_ranges, n_samples)\n",
    "\n",
    "    np.savetxt(\"LHsamples_supply_params.txt\", supply_lhs_samples, fmt='%.6f')\n",
    "    np.savetxt(\"LHsamples_demand_params.txt\", demand_lhs_samples, fmt='%.6f')\n",
    "\n",
    "    demand_flows = generate_demand_flows(demand_lhs_samples)\n",
    "\n",
    "    Qgs = np.loadtxt('meltwater_hist_km3.txt')\n",
    "    Qall = np.loadtxt('total_km3.txt')\n",
    "    rainbase_data = np.loadtxt('rainbase_km3.txt')\n",
    "\n",
    "    supply_flows_folder = './Case3_checks'\n",
    "    rescaled_folder = os.path.join(supply_flows_folder, '1. rescaled_meltwater')\n",
    "    combined_folder = os.path.join(supply_flows_folder, '2. combined')\n",
    "    supply_flows_rescaled_folder = os.path.join(supply_flows_folder, '3. supply_flows_rescaled_combined')\n",
    "    supply_flows_rescaled_FINAL = os.path.join(supply_flows_folder, '4. supply_flows_rescaled_FINAL')\n",
    "    supply_demand_plot_folder = os.path.join(supply_flows_folder, '5. case3_supply_demand_plots')\n",
    "    results_folder = os.path.join(supply_flows_folder, '6. results')\n",
    "    \n",
    "    for folder in [supply_flows_folder, rescaled_folder, combined_folder, supply_flows_rescaled_folder, \n",
    "                   supply_flows_rescaled_FINAL, supply_demand_plot_folder, results_folder]:\n",
    "        assure_path_exists(folder)\n",
    "\n",
    "    ComponentRescaling(sites, Qgs, supply_lhs_samples, rescaled_folder)\n",
    "    CombineRescaledWithRainbase(sites, n_samples, rescaled_folder, rainbase_data, combined_folder)\n",
    "    CombineSupplyFlows(sites, n_samples, combined_folder, supply_flows_rescaled_folder)\n",
    "    calculate_average_flows(supply_flows_rescaled_folder, supply_flows_rescaled_FINAL, \"FINAL_combined_rescaled\")\n",
    "\n",
    "    supply_data = []\n",
    "    for i in range(n_samples):\n",
    "        try:\n",
    "            supply = np.loadtxt(os.path.join(supply_flows_rescaled_folder, f\"supply_Scenario{i+1}.csv\"), delimiter=',')\n",
    "            supply_data.append(supply)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Warning: supply_Scenario{i+1}.csv not found. Skipping this scenario.\")\n",
    "    \n",
    "    print(f\"Number of supply scenarios loaded: {len(supply_data)}\")\n",
    "\n",
    "    current_storage = 14.3  # km³\n",
    "    potential_storage = 18.0  # km³\n",
    "\n",
    "    annual_scarcity, variability, surplus_capacity, deficit_severity, best_months, worst_months, storage_adequacy, storage_adequacy_points = calculate_var_metrics(supply_data, demand_flows, current_storage, potential_storage)\n",
    "\n",
    "    print(f\"Storage Adequacy - Min: {storage_adequacy.min():.4f}, Max: {storage_adequacy.max():.4f}, Mean: {storage_adequacy.mean():.4f}\")\n",
    "    print(f\"Storage Adequacy Points - Counts: {np.bincount(storage_adequacy_points)}\")\n",
    "\n",
    "    scenario_data = pd.DataFrame({\n",
    "        'Scenario': range(1, n_samples + 1),\n",
    "        'Annual_Scarcity': annual_scarcity,\n",
    "        'Variability': variability,\n",
    "        'Surplus_Capacity': surplus_capacity,\n",
    "        'Deficit_Severity': deficit_severity,\n",
    "        'Storage_Adequacy': storage_adequacy,\n",
    "        'Storage_Adequacy_Points': storage_adequacy_points,\n",
    "        'Best_Months': [month_range_str(m) for m in best_months],\n",
    "        'Worst_Months': [month_range_str(m) for m in worst_months],\n",
    "        'Input_Amplitude': supply_lhs_samples[:, 0],\n",
    "        'Input_lambda': supply_lhs_samples[:, 1]\n",
    "    })\n",
    "\n",
    "    # Save results\n",
    "    scenario_data.to_csv(os.path.join(results_folder, 'complete_results.csv'), index=False)\n",
    "\n",
    "    # Create summary statistics\n",
    "    summary_stats = pd.DataFrame({\n",
    "        'Statistic': ['Mean Annual Scarcity', 'Mean Variability', 'Mean Surplus Capacity', 'Mean Deficit Severity', 'Mean Storage Adequacy', 'Storage Adequacy Points Distribution'],\n",
    "        'Value': [\n",
    "            np.mean(annual_scarcity),\n",
    "            np.mean(variability),\n",
    "            np.mean(surplus_capacity),\n",
    "            np.mean(deficit_severity),\n",
    "            np.mean(storage_adequacy),\n",
    "            str(np.bincount(storage_adequacy_points))\n",
    "        ]\n",
    "    })\n",
    "    summary_stats.to_csv(os.path.join(results_folder, 'summary_statistics.csv'), index=False)\n",
    "\n",
    "    # Plot results\n",
    "    metrics = ['Annual_Scarcity', 'Deficit_Severity', 'Surplus_Capacity', 'Variability', 'Storage_Adequacy_Points']\n",
    "    plot_lambda_vs_amplitude_updated_again(scenario_data, metrics, os.path.join(results_folder, 'Case1_results_5_panels.png'))\n",
    "\n",
    "    print(\"Process completed successfully!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
